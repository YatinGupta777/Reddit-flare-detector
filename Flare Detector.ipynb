{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below code is used so that system points to my virtual environment, kindly adjust it according to your system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/yatingupta/Github/Reddit-flare-detector/env/lib/python3.7/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.labnol.org/internet/web-scraping-reddit/28369/ [Can be used if more tha 1000 posts are required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary libraries\n",
    "import praw\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer    \n",
    "from nltk.corpus import stopwords\n",
    "set(stopwords.words('english'))\n",
    "ps = PorterStemmer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/yatingupta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yatingupta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downloading lib\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Id to scrape\n",
    "my_client_id = \"tlaYd7tsDOqvlQ\"\n",
    "my_client_secret = \"xdRqwLkA07r8ScyJZTMsYUndrSA\"\n",
    "my_user_agent = \"scrapping r/india\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to print full panda data frame to analyze data\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    pd.set_option('display.max_colwidth', 950)\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API to access reddit data\n",
    "reddit = praw.Reddit(client_id=my_client_id, client_secret=my_client_secret, user_agent=my_user_agent)\n",
    "india_subreddit = reddit.subreddit('India')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "<ul>\n",
    "<li>Getting TOP, HOT and NEW posts of reddit using the praw API </li>\n",
    "<li>Many JSON tags are retrived which may or may not be used in future </li>\n",
    "<li>https://github.com/reddit-archive/reddit/wiki/JSON used to study the tags </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_posts = []\n",
    "for post in india_subreddit.top(limit=1000):\n",
    "    top_posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created,post.link_flair_text])\n",
    "\n",
    "hot_posts = []\n",
    "for post in india_subreddit.hot(limit=1000):\n",
    "    hot_posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created,post.link_flair_text])\n",
    "\n",
    "\n",
    "new_posts = []\n",
    "for post in india_subreddit.new(limit=1000):\n",
    "    new_posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created,post.link_flair_text])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_posts = pd.DataFrame(top_posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created','flare'])\n",
    "top_text_flare_data = top_posts[['id','title','body','flare']]\n",
    "\n",
    "hot_posts = pd.DataFrame(hot_posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created','flare'])\n",
    "hot_text_flare_data = hot_posts[['id','title','body','flare']]\n",
    "\n",
    "new_posts = pd.DataFrame(new_posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created','flare'])\n",
    "new_text_flare_data = new_posts[['id','title','body','flare']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non-Political                       531\n",
       "Coronavirus                         417\n",
       "Politics                            400\n",
       "AskIndia                            156\n",
       "Photography                          51\n",
       "Policy/Economy                       46\n",
       "[R]eddiquette                        35\n",
       "Sports                               35\n",
       "Business/Finance                     34\n",
       "Science/Technology                   31\n",
       "Unverified                           16\n",
       "Food                                 16\n",
       "CAA-NRC                              10\n",
       "Scheduled                             9\n",
       "r/all                                 3\n",
       "CAA-NRC-NPR                           3\n",
       "AMA                                   2\n",
       "Demonetization                        2\n",
       "/r/all                                2\n",
       "Policy & Economy                      2\n",
       "On Internet Shutdowns                 1\n",
       "Misleading Headline                   1\n",
       "Original Comics                       1\n",
       "Misleading                            1\n",
       "40 Martyrs                            1\n",
       "Politics [Megathread]                 1\n",
       "Lifehacks                             1\n",
       "Announcement                          1\n",
       "Post link Directly                    1\n",
       "Entertainment                         1\n",
       "Goal Achieved!!!                      1\n",
       "Official Sadness Thread               1\n",
       "Translation provided in comments      1\n",
       "Zoke Tyme                             1\n",
       "OC                                    1\n",
       "Politics -- Source in comments        1\n",
       "Policy/Economy -2017 Article          1\n",
       "| Not specific to India |             1\n",
       "Totally real                          1\n",
       "Name: flare, dtype: int64"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_text_flare_data = top_posts[['id','title','body','flare']]\n",
    "hot_text_flare_data = hot_posts[['id','title','body','flare']]\n",
    "new_text_flare_data = new_posts[['id','title','body','flare']]\n",
    "\n",
    "frames = [top_text_flare_data, hot_text_flare_data, new_text_flare_data]\n",
    "data = pd.concat(frames)\n",
    "data.drop_duplicates(keep='last',inplace=True)\n",
    "data.describe()\n",
    "data['flare'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>flare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>988</td>\n",
       "      <td>988</td>\n",
       "      <td>988</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>988</td>\n",
       "      <td>988</td>\n",
       "      <td>65</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>debi1z</td>\n",
       "      <td>Spotted In Bombay Protests Today</td>\n",
       "      <td></td>\n",
       "      <td>Non-Political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>924</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                             title body          flare\n",
       "count      988                               988  988            987\n",
       "unique     988                               988   65             35\n",
       "top     debi1z  Spotted In Bombay Protests Today       Non-Political\n",
       "freq         1                                 1  924            422"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_text_flare_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>flare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>780</td>\n",
       "      <td>771</td>\n",
       "      <td>237</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>g1nd9a</td>\n",
       "      <td>Late Night Random Discussion Thread !</td>\n",
       "      <td></td>\n",
       "      <td>Coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>539</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                  title body        flare\n",
       "count      780                                    780  780          776\n",
       "unique     780                                    771  237           15\n",
       "top     g1nd9a  Late Night Random Discussion Thread !       Coronavirus\n",
       "freq         1                                      3  539          349"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_text_flare_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>flare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>837</td>\n",
       "      <td>837</td>\n",
       "      <td>837</td>\n",
       "      <td>833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>837</td>\n",
       "      <td>827</td>\n",
       "      <td>257</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>g1q22s</td>\n",
       "      <td>Late Night Random Discussion Thread !</td>\n",
       "      <td></td>\n",
       "      <td>Coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>575</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                  title body        flare\n",
       "count      837                                    837  837          833\n",
       "unique     837                                    827  257           16\n",
       "top     g1q22s  Late Night Random Discussion Thread !       Coronavirus\n",
       "freq         1                                      4  575          371"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text_flare_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Flare Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li> The required data here is extracted from data collected earlier </li>\n",
    "    <li> The TOP, HOT and NEW posts are concatenated in frame </li>\n",
    "    <li> duplicates are removed </li>\n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>flare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1825</td>\n",
       "      <td>1825</td>\n",
       "      <td>1825</td>\n",
       "      <td>1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1825</td>\n",
       "      <td>1815</td>\n",
       "      <td>324</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>a9qr7h</td>\n",
       "      <td>Late Night Random Discussion Thread !</td>\n",
       "      <td></td>\n",
       "      <td>Non-Political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1496</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                  title  body          flare\n",
       "count     1825                                   1825  1825           1820\n",
       "unique    1825                                   1815   324             39\n",
       "top     a9qr7h  Late Night Random Discussion Thread !        Non-Political\n",
       "freq         1                                      4  1496            531"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_text_flare_data = top_posts[['id','title','body','flare']]\n",
    "hot_text_flare_data = hot_posts[['id','title','body','flare']]\n",
    "new_text_flare_data = new_posts[['id','title','body','flare']]\n",
    "\n",
    "frames = [top_text_flare_data, hot_text_flare_data, new_text_flare_data]\n",
    "data = pd.concat(frames)\n",
    "data.drop_duplicates(keep='last',inplace=True)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the number of flare was large (40), all the flares with less than 3 posts are deleted here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>flare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1787</td>\n",
       "      <td>1777</td>\n",
       "      <td>316</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>a9qr7h</td>\n",
       "      <td>Late Night Random Discussion Thread !</td>\n",
       "      <td></td>\n",
       "      <td>Non-Political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1466</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                  title  body          flare\n",
       "count     1787                                   1787  1787           1787\n",
       "unique    1787                                   1777   316             14\n",
       "top     a9qr7h  Late Night Random Discussion Thread !        Non-Political\n",
       "freq         1                                      4  1466            531"
      ]
     },
     "execution_count": 748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.groupby('flare').filter(lambda x : len(x)>3)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Creating a text column which concatenates the title and body text </li>\n",
    "<li> ALL the rows with NONE data are removed </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>flare</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1787</td>\n",
       "      <td>1777</td>\n",
       "      <td>316</td>\n",
       "      <td>14</td>\n",
       "      <td>1779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>a9qr7h</td>\n",
       "      <td>Late Night Random Discussion Thread !</td>\n",
       "      <td></td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>Late Night Random Discussion Thread ! ^Beep ^B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1466</td>\n",
       "      <td>531</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                  title  body          flare  \\\n",
       "count     1787                                   1787  1787           1787   \n",
       "unique    1787                                   1777   316             14   \n",
       "top     a9qr7h  Late Night Random Discussion Thread !        Non-Political   \n",
       "freq         1                                      4  1466            531   \n",
       "\n",
       "                                                     text  \n",
       "count                                                1787  \n",
       "unique                                               1779  \n",
       "top     Late Night Random Discussion Thread ! ^Beep ^B...  \n",
       "freq                                                    3  "
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['title'].str.cat(data['body'], sep =\" \")\n",
    "data = data.mask(data.eq('None')).dropna()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the data\n",
    "<ul>\n",
    "    <li>Creating regex emoji pattern to remove emojis</li>\n",
    "    <li> All strings are lowered </li>\n",
    "    <li> Punctuation, whitespaces,links are removed</li>\n",
    "    <li> Stop words are removed and words are stemmed</li>\n",
    "    <li> Finally it contains list of strings where each word is stemmed and cleaned</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "                       u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                       u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                       u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                       u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                       u\"\\U00002702-\\U000027B0\"\n",
    "                       u\"\\U000024C2-\\U0001F251\"\n",
    "                       \"]+\", flags=re.UNICODE)\n",
    "\n",
    "data['text'] = (data['text'].str.lower() #lowercase\n",
    "                           .str.replace(r'[^\\w\\s]+', '') #rem punctuation \n",
    "                           .str.replace(emoji_pattern, '') #rem emoji\n",
    "                           .str.replace(r'http\\S+','') #rem links\n",
    "                           .str.strip() #rem trailing whitespaces\n",
    "                           .str.split()) #split by whitespaces\n",
    "\n",
    "res = []\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "for i in data['text']:\n",
    "    t = \"\"\n",
    "    for j in i:\n",
    "        if j not in stop_words:\n",
    "            w = ps.stem(j)\n",
    "            t += w\n",
    "            t += \" \"\n",
    "    res.append(t)\n",
    "data['text'] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training and validation datasets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(data['text'], data['flare'],test_size=0.3)\n",
    "\n",
    "# X = the entire text data , Y = entire target or flares\n",
    "X = data['text']\n",
    "Y = data['flare']\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# label encode the target variable \n",
    "Y = encoder.fit_transform(Y)\n",
    "train_y = encoder.transform(train_y)\n",
    "test_y = encoder.transform(test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the words to vectors using Tfidf to be used for ML algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(data['text'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(train_x)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(test_x)\n",
    "X = Tfidf_vect.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Accuracy of different ML algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  54.00372439478585\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,train_y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "accuracy_naive = accuracy_score(predictions_NB, test_y)*100\n",
    "\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, test_y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  56.61080074487895\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf,train_y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "accuracy_SVM = accuracy_score(predictions_SVM, test_y)*100\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, test_y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy Score ->  53.81750465549349\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "random_forest_classfier = ensemble.RandomForestClassifier()\n",
    "random_forest_classfier.fit(Train_X_Tfidf,train_y)\n",
    "predictions_RF = random_forest_classfier.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "accuracy_rfc = accuracy_score(predictions_RF, test_y)*100\n",
    "print(\"RF Accuracy Score -> \",accuracy_score(predictions_RF, test_y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDClassifier \n",
    "linear classifier optimized by the SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Accuracy Score ->  57.16945996275605\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "sgd.fit(Train_X_Tfidf,train_y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_sgd = sgd.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "accuracy_sgd = accuracy_score(predictions_sgd, test_y)*100\n",
    "print(\"SGD Accuracy Score -> \",accuracy_score(predictions_sgd, test_y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic_Regression Accuracy Score ->  53.63128491620112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "Logistic_Regression = LogisticRegression(n_jobs=1, C=1e5,max_iter=2000)\n",
    "Logistic_Regression.fit(Train_X_Tfidf,train_y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_Logistic_Regression = Logistic_Regression.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "accuracy_lr = accuracy_score(predictions_Logistic_Regression, test_y)*100\n",
    "print(\"Logistic_Regression Accuracy Score -> \",accuracy_score(predictions_Logistic_Regression, test_y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by Naive = 54.00372439478585%\n",
      "Accuracy by SVM = 56.61080074487895%\n",
      "Accuracy by random_forest_classfier = 53.81750465549349%\n",
      "Accuracy by sgd = 57.16945996275605%\n",
      "Accuracy by Logistic_Regression = 53.63128491620112%\n"
     ]
    }
   ],
   "source": [
    "model_prediction = [accuracy_naive,accuracy_SVM,accuracy_rfc,accuracy_sgd,accuracy_lr]\n",
    "model_names = [\"Naive\",\"SVM\",\"random_forest_classfier\",\"sgd\",\"Logistic_Regression\"]\n",
    "for i in range(0,len(models)):\n",
    "    print(\"Accuracy by \" + model_names[i] + \" = \" + str(model_prediction[i]) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nkfold = model_selection.KFold(n_splits=10)\\nmodel = ensemble.RandomForestClassifier()\\nresults = model_selection.cross_val_score(model, X, Y, cv=kfold)\\nprint(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))\\n\\n'"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "model = ensemble.RandomForestClassifier()\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))\n",
    "\n",
    "\"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on Manual Examples\n",
    "below example list is created on which the models will predict the flare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_list = np.array([\"Stuck in quarantine. Playing games all day\",\"This. virus is killing me\",\"Government of India needs to take action \",\"All the political ministers need to work for india\"])\n",
    "Example = pd.Series(example_list)\n",
    "Example = (Example.str.lower() #lowercase\n",
    "                           .str.replace(r'[^\\w\\s]+', '') #rem punctuation \n",
    "                           .str.replace(emoji_pattern, '') #rem emoji\n",
    "                           .str.replace(r'http\\S+','') #rem links\n",
    "                           .str.strip() #rem trailing whitespaces\n",
    "                           .str.split()) #split by whitespaces\n",
    "res = []\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "for i in Example:\n",
    "    t = \"\"\n",
    "    for j in i:\n",
    "        if j not in stop_words:\n",
    "            w = ps.stem(j)\n",
    "            t += w\n",
    "            t += \" \"\n",
    "    res.append(t)\n",
    "Example = res\n",
    "Example_Tfidf = Tfidf_vect.transform(Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions by Naive\n",
      "['Non-Political' 'Coronavirus' 'Coronavirus' 'Coronavirus']\n",
      "Predictions by SVM\n",
      "['Non-Political' 'Coronavirus' 'Coronavirus' 'Politics']\n",
      "Predictions by random_forest_classfier\n",
      "['Non-Political' 'Politics' 'Politics' 'Politics']\n",
      "Predictions by sgd\n",
      "['Non-Political' 'Non-Political' 'Politics' 'Politics']\n",
      "Predictions by Logistic_Regression\n",
      "['Non-Political' 'Policy/Economy' 'Coronavirus' 'Politics']\n"
     ]
    }
   ],
   "source": [
    "models = [Naive,SVM,random_forest_classfier,sgd,Logistic_Regression]\n",
    "for i in range(0,len(models)):\n",
    "    model = models[i]\n",
    "    predict_example = model.predict(Example_Tfidf)\n",
    "    print(\"Predictions by \" + model_names[i])\n",
    "    print(encoder.inverse_transform(predict_example))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below code will download the model, tfidf vectorizer and encoder to be directly used in Web App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open(\"model.pkl\",\"wb\"))\n",
    "pickle.dump(Tfidf_vect, open(\"tfidf.pickle\", \"wb\"))\n",
    "np.save('classes.npy', encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is used to test the endpoint by sending request from test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'https://www.reddit.com/r/india/comments/fuug0q/ive_never_felt_so_helpless_please_help_our_family/?utm_medium=android_app&utm_source=share': 'Coronavirus', 'https://www.reddit.com/r/india/comments/fzobyi/anyone_else_sick_of_news_reporting_what/?utm_medium=android_app&utm_source=share': 'Non-Political', 'https://www.reddit.com/r/nextfuckinglevel/comments/g289tw/the_needle_galaxy_is_nearly_50_million_lightyears/': 'Non-Political'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "with open('test.txt', 'rb') as f:\n",
    "    r = requests.post('http://127.0.0.1:5000/automated_testing', files={'test.txt': f})\n",
    "    a = r.json()\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
